sample_rate: 16000
n_fft: 768
hop_length: 192
n_mels: 80

model:
  encoder_n_channels: 8
  n_speakers: 110
  speaker_embed_path: '/root/storage/TTS/vctk/speaker_embeds.npy'

  quantize:
    dim: 1
    n_embed: 512

  generator:
    _target_: modules.Generator
    initial_channel: 512
    resblock_kernel_sizes: [3,7,11]
    resblock_dilation_sizes: [[1,3,5], [1,3,5], [1,3,5]]
    upsample_rates: [4,4,2,2]
    upsample_kernel_sizes: [8,8,4,4]
    gin_channels: 192 # 256

  mel_cfg:
    sample_rate: ${sample_rate}
    n_fft: ${n_fft}
    hop_length: ${hop_length}
    n_mels: ${n_mels}
    f_max: 8000

  latent_loss_weight: 10
  l1_factor: 45

optim:
  _target_: torch.optim.AdamW
  lr: 0.0001
  betas: [ 0.8, 0.99 ]

train_cfg:
  dataset:
    _target_: dataset.VQVAEParallel
    # manifest: '/root/storage/TTS/vctk/manifests/train_manifest.txt'
    manifest: '/root/storage/TTS/avc/manifests/avc_train_gen_w_predicted_durs.txt'
    speaker_mapping: '/root/andrey_b/vits/filelists/avc_vctk_speaker_mapping.txt'
    num_samples: 10240

  dataloader:
    batch_size: 16
    num_workers: 4
    shuffle: True

val_cfg:
  dataset:
    _target_: dataset.VQVAEParallel
    manifest: '/root/storage/TTS/vctk/manifests/val_manifest.txt'
    speaker_mapping: '/root/andrey_b/vits/filelists/avc_vctk_speaker_mapping.txt'
    num_samples: -1

  dataloader:
    batch_size: 16
    num_workers: 4
    shuffle: False

trainer:
  gpus: -1
  accelerator: ddp
  max_steps: 500000
  flush_logs_every_n_steps: 200
  log_every_n_steps: 100
  val_check_interval: 1.0

